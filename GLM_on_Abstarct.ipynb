{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "seed = 1\n",
    "train = pd.read_csv('/home/sergey/R_Analyttics_Edge_MITx/kaggle/NYTimesBlogTrain.csv')\n",
    "test = pd.read_csv('/home/sergey/R_Analyttics_Edge_MITx/kaggle/NYTimesBlogTest.csv')\n",
    "combo = pd.merge(train, test, how='outer')\n",
    "combo = combo.drop('Popular', axis=1)\n",
    "y = train['Popular']\n",
    "combo_clean = combo.fillna('empty')\n",
    "combo_clean['LogWC'] = np.log(.1+ combo_clean['WordCount'])\n",
    "\n",
    "#Extract Date/time info and bin time\n",
    "import datetime as dt\n",
    "combo_clean['date'] = combo_clean['PubDate'].apply(\n",
    "    lambda x: dt.datetime.strptime(x, '%Y-%m-%d %H:%M:%S').strftime('%A')\n",
    ")\n",
    "combo_clean['hour'] = combo_clean['PubDate'].apply(\n",
    "    lambda x: int(dt.datetime.strptime(x, '%Y-%m-%d %H:%M:%S').strftime('%H'))\n",
    ")\n",
    "combo_clean[['PubDate','date','hour']][1:5]\n",
    "bins = np.linspace(0,24,5)\n",
    "labels = ['night', 'morning', 'afternoon', 'evening']\n",
    "combo_clean['hour_bins'] = pd.cut(combo_clean['hour'], bins=bins, labels=labels)\n",
    "combo_clean.drop(['hour', 'WordCount', 'PubDate'], axis=1, inplace=True)\n",
    "\n",
    "#Make dummies and bags of words\n",
    "import sklearn.feature_extraction.text as txt\n",
    "categorical_dummies = pd.get_dummies(combo_clean[['NewsDesk','SectionName','SubsectionName','date']])\n",
    "categorical_hours = pd.get_dummies(combo_clean['hour_bins'].apply(str))\n",
    "\n",
    "\n",
    "tfidf = txt.TfidfVectorizer(stop_words='english', min_df=10, ngram_range=(1, 2),)\n",
    "\n",
    "\n",
    "bwAbstract       = (tfidf.fit_transform(combo_clean['Abstract'])).todense()\n",
    "\n",
    "\n",
    "#Put everything together\n",
    "data = np.concatenate((categorical_dummies,\n",
    "                       categorical_hours,\n",
    "                       combo_clean['LogWC'].to_frame(),\n",
    "                       bwAbstract), axis=1)\n",
    "\n",
    "data_train = data[: train.shape[0],:]\n",
    "data_test  = data[train.shape[0]:,:]\n",
    "import sklearn.cross_validation as cv\n",
    "data_train, data_val, y_train, y_val = cv.train_test_split(data_train, y, test_size=.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5225, 2531)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "import sklearn.cross_validation as cv\n",
    "import sklearn.grid_search as grd\n",
    "import sklearn.metrics as mts\n",
    "import sklearn.ensemble as ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='auto', dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_mod = lm.LogisticRegression(random_state=seed, class_weight='auto')\n",
    "lg_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(labels=[0 0 ..., 1 0], n_iter=5, test_size=0.2, random_state=1),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight='auto', dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([  1.00000e-02,   1.20679e-02,   1.45635e-02,   1.75751e-02,\n",
       "         2.12095e-02,   2.55955e-02,   3.08884e-02,   3.72759e-02,\n",
       "         4.49843e-02,   5.42868e-02,   6.55129e-02,   7.90604e-02,\n",
       "         9.54095e-02,   1.15140e-01,   1.38950e-01,   1.6...    3.90694e+01,   4.71487e+01,   5.68987e+01,   6.86649e+01,\n",
       "         8.28643e+01,   1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = cv.StratifiedShuffleSplit(y_train, random_state=seed, n_iter=5, test_size=.2)\n",
    "param = {'C': np.logspace(-2,2.,50),\n",
    "        'penalty': ['l1', 'l2']}\n",
    "gr = grd.GridSearchCV(lg_mod, param_grid=param, scoring = 'roc_auc', cv=folds)\n",
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 5min 48s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "gr.fit(data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.325711365590108, class_weight='auto', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', penalty='l2', random_state=1,\n",
       "          solver='liblinear', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94260202428625106"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate LogisticRegression on held-out set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we had a parameter `refit=True` in GridSearchCV we do not need to refit on the whole train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93146730206325401"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mts.roc_auc_score(y_val, gr.best_estimator_.predict_proba(data_val)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "etc_mod = ens.ExtraTreesClassifier(class_weight='auto', n_jobs=-1, n_estimators=3000)\n",
    "scores = cv.cross_val_score(etc_mod, data_train, y_train, scoring='roc_auc', cv=folds, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC is 0.93390 \n",
      "Standard deviation of AUC is 0.00721\n"
     ]
    }
   ],
   "source": [
    "print('Mean AUC is %0.5f \\nStandard deviation of AUC is %0.5f' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC on held-out set is 0.92983\n"
     ]
    }
   ],
   "source": [
    "etc_mod.fit(data_train, y_train)\n",
    "print('Mean AUC on held-out set is %0.5f' % mts.roc_auc_score(y_val, etc_mod.predict_proba(data_val)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_mod = ens.AdaBoostClassifier(random_state=seed)\n",
    "ada_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "params = {'n_estimators': [1000, 3000, 10000],\n",
    "          'learning_rate': st.uniform(loc=.00001,scale= .5)\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedShuffleSplit(labels=[0 0 ..., 1 0], n_iter=5, test_size=0.2, random_state=1),\n",
       "          error_score='raise',\n",
       "          estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=1),\n",
       "          fit_params={}, iid=True, n_iter=20, n_jobs=-1,\n",
       "          param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fd67114db38>, 'n_estimators': [1000, 3000, 10000]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgrid_search = grd.RandomizedSearchCV(ada_mod, param_distributions = params,\n",
    "                                      n_iter=20, scoring='roc_auc',\n",
    "                                      random_state=seed, cv=folds, n_jobs=-1)\n",
    "rgrid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 21h 45min 30s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "rgrid_search.fit(data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93347653668208863"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgrid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=0.018598112002693002, n_estimators=10000,\n",
       "          random_state=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgrid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.018598112002693002, 'n_estimators': 10000}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgrid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC on held-out set is 0.91844\n"
     ]
    }
   ],
   "source": [
    "print('Mean AUC on held-out set is %0.5f' % \n",
    "      mts.roc_auc_score(y_val, rgrid_search.best_estimator_.predict_proba(data_val)[:,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
